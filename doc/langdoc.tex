%
% File acl2018.tex
%
%% Based on the style files for ACL-2017, with some changes, which were, in turn,
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper,usenames,dvipsnames]{article}
\usepackage[hyperref]{acl2018}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

\usepackage{xcolor}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Finding the Most Helpful Language to Adapt From for Endangered Languages}

\author{Chian-Yu Chen, Jean Lee, Zirui Li, Yu-Hsiang Lin, Yuyan Zhang, Graham Neubig \\
  Language Technologies Institute \\
  Carnegie Mellon University \\
  {\tt \{chianyuc, jeanl1, ziruil, yuhsianl, yuyanz1\}@andrew.cmu.edu} \\
  {\tt gneubig@cs.cmu.edu} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
{\color{blue}Abstract.}
\end{abstract}

\section{Introduction}

The common challenge of applying natural language processing (NLP) techniques to documenting the endangered languages is lack of language data. Moreover, among the limited data, there is often only a small portion of it that is annotated. Because the latest NLP technologies such as machine translation or speech recognition usually depends on a large quantity of annotated data, their performance is poor when directly applied to the endangered languages.

It has been shown that by using multi-lingual learning one can leverage one or more similar high-resource languages to improve the performance on the low-resource languages in several NLP tasks. One example is that by combining the training data of one or more high-resource languages with that of the target low-resource language to form a larger training dataset, one can obtain higher BLEU score in machine translation tasks \citep{Neubig2018}. It is therefore compelling to conduct a thorough investigation on the effective way of performing language adaptation in several common NLP tasks.


\section{Finding the Most Helpful Language for Adaptation}

The questions we try to answer are:

\begin{enumerate}

\item Given a NLP task, a target low-resource language and its dataset, and some high-resource languages and their datasets, how can one find out which auxiliary high-resource language is the most helpful to adapt from, without exhaustively performing the task on all possible choices?

\item Does there exist language or dataset features that are common strong indicators across multiple tasks? Or the strong features are highly task-dependent?

\item How does the performance of the method scales as the size of the dataset decreases? Could it be applied to resource-constrained endangered languages?

\end{enumerate}

To answer the first question, we look at a few features that may be representative for the language and/or the particular dataset, and try to find the correlation between them and the quality of adaptation. More precisely, the features we consider include:

\begin{enumerate}
\item Dataset size
\item Token-type ratio (TTR) of the dataset
\item Word-level/character-level overlap {\color{red}ratio} between the target language dataset and auxiliary language dataset
\item URIEL distance between task and auxiliary language (dataset independent) {\color{blue}(more details\dots)}
{\color{blue}\item Earth-mover distance}
\end{enumerate}

\noindent We formulate our problem as: given the dataset of the low-resource task language, and a set of datasets of the high-resource auxiliary languages, predict which auxiliary language would help improving the performance most. There are at least three possible paradigms to address this prediction problem:

\begin{enumerate}

\item Regression: directly predict the task metric score.

\item Ranking: predict the order of the auxiliary language according to how much they improve the performance.

\item Binary classification: only predict which one language will be the most helpful.

\end{enumerate}

To answer the second question, we consider the following common NLP tasks: machine translation, entity linking, and {\color{blue}[SOME TASK]}. In choosing the models, we prefer the ones that are easy to interpret, so that it is easier to tell the relative importance among the features. In this work, we consider decision trees as our models.

To answer the third question, we start with languages that include both low-resource and high-resource languages, and decrease the data size to observe the effect. We use TED dataset that include 54 languages.


\section{Experiments}

{\color{blue}Experiments.}


\section{Related Works}

{\color{blue}Related Works.}


\section{Conclusion}

{\color{blue}Conclusion.}


\bibliography{MachineLearning}
\bibliographystyle{acl_natbib}

\end{document}
